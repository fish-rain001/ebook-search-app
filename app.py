import os
import glob
import re
import threading
import html
import streamlit as st

from logic import word_engine as we
from logic import ai_engine as ai


# =========================
# é¡µé¢é…ç½®
# =========================
st.set_page_config(
    page_title="ç”µå­ä¹¦ä¸“æ æ£€ç´¢ç³»ç»Ÿ",
    layout="wide"
)

st.title("ğŸ“š ç”µå­ä¹¦ä¸“æ æ£€ç´¢ç³»ç»Ÿï¼ˆStreamlitï¼‰")


# =========================
# å·¥å…·ï¼šé«˜äº®å…³é”®è¯
# =========================
def highlight_text(text, keyword):
    if not text or not keyword:
        return html.escape(text)

    escaped = html.escape(text)

    pattern = re.compile(re.escape(keyword), re.IGNORECASE)

    return pattern.sub(
        lambda m: f"<mark style='background-color:#ffe066'>{m.group(0)}</mark>",
        escaped
    )


# =========================
# æœç´¢ç¼“å­˜
# =========================
@st.cache_data(show_spinner=False)
def cached_full_text_search(doc_path, keyword):
    return we.full_text_search(doc_path, keyword)


@st.cache_data(show_spinner=False)
def cached_global_search(all_docs, keyword):
    results = {
        "topics": [],
        "contents": [],
        "tables": []
    }

    for p in all_docs:
        try:
            r = we.full_text_search(p, keyword)

            year = os.path.basename(os.path.dirname(p))
            issue = os.path.basename(p)

            for x in r["topics"]:
                x.update({"year": year, "issue": issue})
                results["topics"].append(x)

            for x in r["contents"]:
                x.update({"year": year, "issue": issue})
                results["contents"].append(x)

            for x in r["tables"]:
                x.update({"year": year, "issue": issue})
                results["tables"].append(x)

        except Exception:
            continue

    return results


# =========================
# å·¦ä¾§ï¼šæ–‡æ¡£é€‰æ‹©
# =========================
with st.sidebar:
    st.header("ğŸ“‚ æ–‡æ¡£é€‰æ‹©")

    years = we.list_years()
    if not years:
        st.error("æœªæ£€æµ‹åˆ° data/ç”µå­ä¹¦ ç›®å½•")
        st.stop()

    year_index = (
        years.index(st.session_state["jump_year"])
        if "jump_year" in st.session_state and st.session_state["jump_year"] in years
        else 0
    )
    year = st.selectbox("é€‰æ‹©å¹´ä»½", years, index=year_index)

    issues = we.list_issues(year)
    if not issues:
        st.warning("è¯¥å¹´ä»½ä¸‹æœªå‘ç° Word æ–‡ä»¶")
        st.stop()

    issue_index = (
        issues.index(st.session_state["jump_issue"])
        if "jump_issue" in st.session_state and st.session_state["jump_issue"] in issues
        else 0
    )
    issue = st.selectbox("é€‰æ‹©æœŸåˆŠ", issues, index=issue_index)

    doc_path = we.find_doc_path(year, issue)
    if not doc_path:
        st.error("æœªæ‰¾åˆ°å¯¹åº” Word æ–‡æ¡£")
        st.stop()


# =========================
# Tabs
# =========================
tab_read, tab_search, tab_ai = st.tabs(
    ["ğŸ“– ä¸“æ  / ä¸»é¢˜é˜…è¯»", "ğŸ” å…¨æ–‡æœç´¢", "ğŸ¤– AI åˆ†æ"]
)


# ==================================================
# ğŸ“– Tab 1ï¼šé˜…è¯»
# ==================================================
with tab_read:
    st.subheader("ğŸ“– æŒ‰ä¸“æ  / ä¸»é¢˜é˜…è¯»")

    columns = we.list_columns(doc_path)
    if not columns:
        st.warning("æ–‡æ¡£ä¸­æœªè¯†åˆ«åˆ°ã€æ ‡é¢˜1ã€‘ä¸“æ ")
        st.stop()

    col1, col2 = st.columns([1, 2])

    column_index = (
        columns.index(st.session_state["jump_column"])
        if "jump_column" in st.session_state and st.session_state["jump_column"] in columns
        else 0
    )
    with col1:
        column = st.selectbox("é€‰æ‹©ä¸“æ ", columns, index=column_index)

    topics = we.list_topics(doc_path, column)

    topic_index = (
        topics.index(st.session_state["jump_topic"])
        if "jump_topic" in st.session_state and st.session_state["jump_topic"] in topics
        else 0
    )

    with col2:
        topic = st.selectbox("é€‰æ‹©ä¸»é¢˜", topics, index=topic_index) if topics else None

    if topic:
        st.markdown("---")
        st.markdown(f"### {topic}")

        content = we.get_topic_content(doc_path, column, topic)

        for block in content:
            if isinstance(block, dict) and "table" in block:
                st.table(block["table"])
            else:
                st.write(block)


# ==================================================
# ğŸ” Tab 2ï¼šå…¨æ–‡æœç´¢ï¼ˆå«é«˜äº®ï¼‰
# ==================================================
with tab_search:
    st.subheader("ğŸ” å…¨æ–‡æœç´¢ï¼ˆé«˜äº®å‘½ä¸­è¯ï¼‰")

    keyword = st.text_input("è¾“å…¥å…³é”®è¯")
    global_mode = st.checkbox("ğŸŒ åˆ‡æ¢ä¸ºå…¨å±€æœç´¢æ¨¡å¼")

    if st.button("å¼€å§‹æœç´¢"):
        if not keyword.strip():
            st.warning("è¯·è¾“å…¥å…³é”®è¯")
            st.stop()

        if not global_mode:
            results = cached_full_text_search(doc_path, keyword)
        else:
            book_root = os.path.join("data", "ç”µå­ä¹¦")
            all_docs = glob.glob(
                os.path.join(book_root, "**", "*.docx"),
                recursive=True
            )
            with st.spinner(f"æ­£åœ¨å…¨å±€æœç´¢ {len(all_docs)} ä¸ª Word æ–‡ä»¶..."):
                results = cached_global_search(all_docs, keyword)

        total = len(results["topics"]) + len(results["contents"]) + len(results["tables"])

        if total == 0:
            st.info("æœªæ‰¾åˆ°åŒ¹é…å†…å®¹")
            st.stop()

        st.success(f"å…±æ‰¾åˆ° {total} æ¡ç»“æœ")
        idx = 1

        for r in results["topics"]:
            title = f"[{r.get('year','')}] {r.get('issue','')} ï½œ {r['column']} â†’ {r.get('topic','')}"
            with st.expander(f"{idx}. ã€æ ‡é¢˜ã€‘{title}"):
                st.markdown(
                    highlight_text(r["hit"], keyword),
                    unsafe_allow_html=True
                )

                if st.button("ğŸ“– è·³è½¬é˜…è¯»", key=f"jump_t_{idx}"):
                    st.session_state.update({
                        "jump_year": r.get("year"),
                        "jump_issue": r.get("issue"),
                        "jump_column": r.get("column"),
                        "jump_topic": r.get("topic")
                    })
                    st.experimental_rerun()
            idx += 1

        for r in results["contents"]:
            title = f"[{r.get('year','')}] {r.get('issue','')} ï½œ {r['column']} â†’ {r.get('topic','')}"
            with st.expander(f"{idx}. ã€æ­£æ–‡ã€‘{title}"):
                st.markdown(
                    highlight_text(r["content"], keyword),
                    unsafe_allow_html=True
                )

                if st.button("ğŸ“– è·³è½¬é˜…è¯»", key=f"jump_c_{idx}"):
                    st.session_state.update({
                        "jump_year": r.get("year"),
                        "jump_issue": r.get("issue"),
                        "jump_column": r.get("column"),
                        "jump_topic": r.get("topic")
                    })
                    st.experimental_rerun()
            idx += 1

        for r in results["tables"]:
            title = f"[{r.get('year','')}] {r.get('issue','')} ï½œ {r['column']} â†’ {r.get('topic','')}"
            with st.expander(f"{idx}. ã€è¡¨æ ¼ã€‘{title}"):
                highlighted_rows = [
                    [highlight_text(c, keyword) for c in row]
                    for row in r["content"]
                ]
                st.markdown(
                    "<br>".join([" | ".join(row) for row in highlighted_rows]),
                    unsafe_allow_html=True
                )
            idx += 1


# ==================================================
# ğŸ¤– Tab 3ï¼šAI åˆ†æ
# ==================================================
with tab_ai:
    st.subheader("ğŸ¤– AI å­¦æœ¯è¾…åŠ©åˆ†æ")

    source = st.radio("åˆ†æå¯¹è±¡", ["å½“å‰ä¸»é¢˜å†…å®¹", "è‡ªå®šä¹‰æ–‡æœ¬"])

    if source == "å½“å‰ä¸»é¢˜å†…å®¹":
        if not topic:
            st.warning("è¯·å…ˆé€‰æ‹©ä¸»é¢˜")
            st.stop()
        text = "\n".join(t for t in content if isinstance(t, str))
    else:
        text = st.text_area("è¾“å…¥åˆ†ææ–‡æœ¬", height=260)

    if st.button("å¼€å§‹ AI åˆ†æ"):
        placeholder = st.empty()

        def run_ai():
            try:
                placeholder.markdown("### ğŸ“Œ æ‘˜è¦")
                placeholder.write(ai.summarize_text(text))
                placeholder.markdown("### ğŸ· å…³é”®è¯")
                placeholder.write(ai.extract_keywords(text))
                placeholder.markdown("### ğŸ§  å­¦æœ¯åˆ†æ")
                placeholder.write(ai.analyze_topic(text))
            except Exception as e:
                placeholder.error(str(e))

        threading.Thread(target=run_ai).start()




